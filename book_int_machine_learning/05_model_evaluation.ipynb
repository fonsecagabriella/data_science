{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation\n",
    "\n",
    "## 5.1 Cross-validation\n",
    "\n",
    "**k-fold cross-validation**: Instead of having only one set of train/test, we have several cuts in the data split differently to compute the average test score. (usually between 5 - 10)\n",
    "\n",
    "Looking at the range of scores in the folds gives us an idea on how well the model will be able to generalise to knew data. To summarise the performance of the model, we use the mean.\n",
    "\n",
    "**Stratified k-fold cross-validation** is used by default in classification in scikit-learn. This means it considers how your data is split and follows this split in the generated train and test sets. For example, if your data has 90% label A and 10% label B, in each fold you have 90% label A samples and 10% label B samples. \n",
    "\n",
    "**IMPORTANT** Cross-validation is not a way to create a model that will be able to predict on new data. It only gives you information on how well a given algorithm will generalise on a specific dataset. The cross validation does not return a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.96666667 1.         0.93333333 0.96666667 1.        ]\n",
      "Mean cross-validation: 0.973\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "logreg = LogisticRegression(max_iter=100000)\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=5)\n",
    "#by default it produces 5 folds, but we can change the CV parameter\n",
    "\n",
    "print(f\"Cross-validation scores: {scores}\")\n",
    "print(f\"Mean cross-validation: {scores.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CV parameter can be fine-adjusted. Let's say that instead of using the default stratified K-fold, you wanted to reproduce some results, and go with the k-fold instead. You can do that by adjusting the CV parameter as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0. 0. 0.]\n",
      "Cross-validation scores with shuffling: [0.98 0.96 0.96]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=3)\n",
    "print(f\"Cross-validation scores: {cross_val_score(logreg, iris.data, iris.target, cv=kfold)}\")\n",
    "# we will get a score of 0 0 0 because the data is ordered in way that the first points all belong to the same class\n",
    "\n",
    "\n",
    "# another strategy instead of using stratified k-fold is to produce a suffling of the data\n",
    "# but then remember to use random_state in order to get reproducible results\n",
    "kfold_shuffle = KFold(n_splits=3, shuffle=True, random_state=0)\n",
    "print(f\"Cross-validation scores with shuffling: {cross_val_score(logreg, iris.data, iris.target, cv=kfold_shuffle)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Leave-one-out cross-validation** is like a k-fold, but each fold is a single sample. It is not used very much because it is time-consuming, but it can be useful in small datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cv iterations: 150\n",
      "Mean accuracy: 0.97\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
    "\n",
    "print(f\"Number of cv iterations: {len(scores)}\")\n",
    "print(f\"Mean accuracy: {scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
