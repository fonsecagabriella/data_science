{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction the NN\n",
    "\n",
    "In essence: For each epoch, for each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "**NOTE ABOUT NNs: Both the Sequential API and the Functional API are declarative: you start by declar‐ ing which layers you want to use and how they should be connected, and only then can you start feeding the model some data for training or inference.**\n",
    "\n",
    "\n",
    "<img src=\"../img/derivatives_activation.png\" width=\"80%\">\n",
    "\n",
    "*Derivatives: rate of change*\n",
    "\n",
    "\n",
    "**Key Differences Between Perceptron and Neuron**\n",
    "| Feature               | Perceptron                       | Neuron in MLP                   |\n",
    "|-----------------------|-----------------------------------|----------------------------------|\n",
    "| **Activation Function** | Step function                   | Nonlinear (e.g., ReLU, sigmoid) |\n",
    "| **Output**            | Binary (0 or 1)                  | Continuous or nonlinear values  |\n",
    "| **Usage**             | Single-layer models (linear tasks) | Multilayer networks (nonlinear tasks) |\n",
    "| **Problem Solving**   | Only linear separability         | Handles nonlinear problems      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regression MLPs**\n",
    "\n",
    "| Hyperparameter        | Typical Value                                                                 |\n",
    "|-----------------------|------------------------------------------------------------------------------|\n",
    "| # input neurons       | One per input feature (e.g., 28 x 28 = 784 for MNIST)                       |\n",
    "| # hidden layers       | Depends on the problem. Typically 1 to 5.                                   |\n",
    "| # neurons per hidden layer | Depends on the problem. Typically 10 to 100.                            |\n",
    "| # output neurons      | 1 per prediction dimension (if you expect 2 values, then 2 outputs)                                                  |\n",
    "| Hidden activation     | ReLU (or SELU)                                              |\n",
    "| Output activation     | None or ReLU/Softplus (if positive outputs) or Logistic (0 to 1)/Tanh (hyperbolic tangent)(-1 to 1) (if bounded outputs) |\n",
    "| Loss function         | MSE or MAE/Huber (if outliers)                                              |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5053326657968423\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "mse = mean_squared_error(y_valid, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classification MLPs**\n",
    "\n",
    "| Hyperparameter            | Binary classification | Multilabel binary classification | Multiclass classification |\n",
    "|---------------------------|-----------------------|-----------------------------------|---------------------------|\n",
    "| Input and hidden layers   | Same as regression   | Same as regression               | Same as regression       |\n",
    "| # output neurons          | 1                   | 1 per label                      | 1 per class              |\n",
    "| Output layer activation   | Logistic (sigmoid for NNs)           | Logistic                          | Softmax                  |\n",
    "| Loss function   | (binary)Cross-entropy            | (categorical)Cross-entropy                         | (sparse-categorical)Cross-entropy                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], max_iter=10_000,\n",
    "                        random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_valid, y_valid)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple image classifier with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 19:27:54.784462: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# if FETCH WORKS\n",
    "fashion_mnist = tf.keras.datasets.fashion_mnist.load_data()\n",
    "(X_train_full, y_train_full), (X_test, y_test) = fashion_mnist\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, X_test = X_train / 255., X_valid / 255., X_test / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# IF FETCH DOES NOT WORK\n",
    "\n",
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the fashion ds has 10 categories, like mnist, but with clothes\n",
    "\n",
    "def load_idx(filepath):\n",
    "    \"\"\"Load IDX format data from a gzip file.\"\"\"\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        # Read the file content\n",
    "        data = f.read()\n",
    "        # Magic number (first 4 bytes)\n",
    "        magic = int.from_bytes(data[0:4], byteorder='big')\n",
    "        # Number of items (next 4 bytes)\n",
    "        num_items = int.from_bytes(data[4:8], byteorder='big')\n",
    "        if magic == 2049:  # Labels\n",
    "            return np.frombuffer(data[8:], dtype=np.uint8)\n",
    "        elif magic == 2051:  # Images\n",
    "            rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "            cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "            images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "            return images.reshape(num_items, rows, cols)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown magic number in file header!\")\n",
    "\n",
    "# Paths to the data files\n",
    "train_images_path = '../data/fashion/train-images-idx3-ubyte.gz'\n",
    "train_labels_path = '../data/fashion/train-labels-idx1-ubyte.gz'\n",
    "test_images_path = '../data/fashion/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = '../data/fashion/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# Load the data\n",
    "X_train_full = load_idx(train_images_path)\n",
    "y_train_full = load_idx(train_labels_path)\n",
    "X_test = load_idx(test_images_path)\n",
    "y_test = load_idx(test_labels_path)\n",
    "\n",
    "# Normalize the image data\n",
    "# we also need to scale the data, for simplicity we will scale the pixel intensities in the 0-1 range simply dividing them by 255\n",
    "\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Train images shape:\", X_train_full.shape)\n",
    "print(\"Train labels shape:\", y_train_full.shape)\n",
    "print(\"Test images shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will create a validation set\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# extra code\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[100], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class name\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bag'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of class for a given item\n",
    "class_names[y_train[100]]\n",
    "\n",
    "#y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first Keras sequential model - Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabi/codes/data_science/.venv/lib/python3.10/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Flatten(input_shape=[28,28]), # receives input data and converts it to 1d array\n",
    "    keras.layers.Dense(300, activation=\"relu\"), # dense layer with 300 neurons\n",
    "    keras.layers.Dense(100, activation=\"relu\"), # second dense layer with 100 neurons\n",
    "    keras.layers.Dense(10, activation=\"softmax\") #output layer, with 10 nodes, as 10 classes, softmax because multiclass\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get info about the model including output shape of each layer and the number of parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all the layers of a model\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can call each layer by its index\n",
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can het the layer by its name\n",
    "model.get_layer(\"dense_2\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.05403419, -0.00725313, -0.01285256, ...,  0.03761493,\n",
       "        -0.00464329,  0.06443502],\n",
       "       [ 0.06992011, -0.06634848,  0.04443703, ...,  0.0318657 ,\n",
       "         0.06228201,  0.01455625],\n",
       "       [ 0.00581784, -0.04326789, -0.02376759, ..., -0.01441506,\n",
       "        -0.03279389, -0.02729871],\n",
       "       ...,\n",
       "       [-0.01717574,  0.01540208, -0.0136414 , ...,  0.01484972,\n",
       "        -0.06255511, -0.06479155],\n",
       "       [-0.06433344,  0.01617884,  0.01409102, ...,  0.07022028,\n",
       "        -0.00495759,  0.06894739],\n",
       "       [ 0.05657233,  0.05024802,  0.06509876, ...,  0.04280004,\n",
       "        -0.02753646,  0.00013673]], dtype=float32)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all the weights and biases from each layer\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once the model is created you must call compile() and specify the loss function, optimiser, and optionally metrics for evaluation\n",
    "\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", \n",
    "                optimizer=\"sgd\", \n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.6695 - loss: 1.0362 - val_accuracy: 0.8192 - val_loss: 0.5163\n",
      "Epoch 2/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8219 - loss: 0.5084 - val_accuracy: 0.8300 - val_loss: 0.4644\n",
      "Epoch 3/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8449 - loss: 0.4471 - val_accuracy: 0.8418 - val_loss: 0.4526\n",
      "Epoch 4/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4261 - val_accuracy: 0.8594 - val_loss: 0.4009\n",
      "Epoch 5/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 0.3975 - val_accuracy: 0.8644 - val_loss: 0.3879\n",
      "Epoch 6/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.3786 - val_accuracy: 0.8628 - val_loss: 0.3841\n",
      "Epoch 7/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8724 - loss: 0.3670 - val_accuracy: 0.8314 - val_loss: 0.4573\n",
      "Epoch 8/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8746 - loss: 0.3547 - val_accuracy: 0.8690 - val_loss: 0.3714\n",
      "Epoch 9/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.3398 - val_accuracy: 0.8722 - val_loss: 0.3676\n",
      "Epoch 10/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8828 - loss: 0.3354 - val_accuracy: 0.8668 - val_loss: 0.3647\n",
      "Epoch 11/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3254 - val_accuracy: 0.8776 - val_loss: 0.3389\n",
      "Epoch 12/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8856 - loss: 0.3200 - val_accuracy: 0.8730 - val_loss: 0.3516\n",
      "Epoch 13/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.3003 - val_accuracy: 0.8754 - val_loss: 0.3383\n",
      "Epoch 14/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8968 - loss: 0.2942 - val_accuracy: 0.8768 - val_loss: 0.3374\n",
      "Epoch 15/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2967 - val_accuracy: 0.8800 - val_loss: 0.3248\n",
      "Epoch 16/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8964 - loss: 0.2858 - val_accuracy: 0.8836 - val_loss: 0.3274\n",
      "Epoch 17/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8977 - loss: 0.2821 - val_accuracy: 0.8790 - val_loss: 0.3309\n",
      "Epoch 18/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8995 - loss: 0.2774 - val_accuracy: 0.8824 - val_loss: 0.3233\n",
      "Epoch 19/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9036 - loss: 0.2709 - val_accuracy: 0.8778 - val_loss: 0.3340\n",
      "Epoch 20/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9040 - loss: 0.2657 - val_accuracy: 0.8834 - val_loss: 0.3318\n",
      "Epoch 21/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2646 - val_accuracy: 0.8816 - val_loss: 0.3227\n",
      "Epoch 22/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2560 - val_accuracy: 0.8824 - val_loss: 0.3309\n",
      "Epoch 23/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.2505 - val_accuracy: 0.8774 - val_loss: 0.3278\n",
      "Epoch 24/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2503 - val_accuracy: 0.8848 - val_loss: 0.3147\n",
      "Epoch 25/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2396 - val_accuracy: 0.8808 - val_loss: 0.3318\n",
      "Epoch 26/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2380 - val_accuracy: 0.8878 - val_loss: 0.3117\n",
      "Epoch 27/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2314 - val_accuracy: 0.8846 - val_loss: 0.3218\n",
      "Epoch 28/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2280 - val_accuracy: 0.8884 - val_loss: 0.3002\n",
      "Epoch 29/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9210 - loss: 0.2194 - val_accuracy: 0.8866 - val_loss: 0.3153\n",
      "Epoch 30/30\n",
      "\u001b[1m1719/1719\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.2225 - val_accuracy: 0.8868 - val_loss: 0.3176\n"
     ]
    }
   ],
   "source": [
    "# now you fit the model\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=30,\n",
    "            validation_data=(X_valid, y_valid)) #validation data is optional, but desirable\n",
    "\n",
    "            # you can also use validation_split = z, where z is between (0,1), a ratio of X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If the training set was very skewed: use class_weight in fit()\n",
    "- sample_weight can be used in fit if the labels have been set by different people (image labels by experts and labels by a community)\n",
    "- if the loss is still decreasing, it means the model didn't converge yet, and you should continue training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training parameters \n",
      " {'verbose': 'auto', 'epochs': 30, 'steps': 1719}\n",
      "List of epochs \n",
      " [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n",
      "Dictionary of loss and extra metrics \n",
      " {'accuracy': [0.7560363411903381, 0.8291090726852417, 0.8449817895889282, 0.8552181720733643, 0.8621818423271179, 0.8685454726219177, 0.8719817996025085, 0.8751817941665649, 0.8799818158149719, 0.8843454718589783, 0.8841090798377991, 0.8881090879440308, 0.8901636600494385, 0.8950181603431702, 0.895618200302124, 0.8967090845108032, 0.8987454771995544, 0.9005454778671265, 0.9033818244934082, 0.904872715473175, 0.9064000248908997, 0.9082000255584717, 0.9094181656837463, 0.9106181859970093, 0.9128545522689819, 0.9147999882698059, 0.9168182015419006, 0.9171454310417175, 0.9184545278549194, 0.9203454256057739], 'loss': [0.740820586681366, 0.49119457602500916, 0.4438423216342926, 0.4171612858772278, 0.39485105872154236, 0.37822777032852173, 0.36488550901412964, 0.35235610604286194, 0.34012359380722046, 0.33156174421310425, 0.3219189941883087, 0.31461989879608154, 0.30668124556541443, 0.29947301745414734, 0.2927218973636627, 0.2867719531059265, 0.2814587950706482, 0.2757171094417572, 0.26968464255332947, 0.2650150954723358, 0.26034870743751526, 0.25574466586112976, 0.2507575750350952, 0.24652092158794403, 0.24176616966724396, 0.23791390657424927, 0.23349548876285553, 0.22931796312332153, 0.22603799402713776, 0.2210059016942978], 'val_accuracy': [0.8191999793052673, 0.8299999833106995, 0.8417999744415283, 0.8593999743461609, 0.8644000291824341, 0.8628000020980835, 0.8313999772071838, 0.8690000176429749, 0.8722000122070312, 0.8668000102043152, 0.8776000142097473, 0.8730000257492065, 0.8754000067710876, 0.876800000667572, 0.8799999952316284, 0.8835999965667725, 0.8790000081062317, 0.8823999762535095, 0.8777999877929688, 0.883400022983551, 0.881600022315979, 0.8823999762535095, 0.8773999810218811, 0.8848000168800354, 0.8808000087738037, 0.8877999782562256, 0.8845999836921692, 0.8884000182151794, 0.8866000175476074, 0.8867999911308289], 'val_loss': [0.5163423418998718, 0.4644409716129303, 0.4526139795780182, 0.4008602797985077, 0.38786977529525757, 0.38406261801719666, 0.45734933018684387, 0.3713962733745575, 0.36758953332901, 0.364693820476532, 0.33890005946159363, 0.35157498717308044, 0.33829763531684875, 0.3374480903148651, 0.3247562050819397, 0.32743266224861145, 0.33087530732154846, 0.323319673538208, 0.3340303599834442, 0.3317694067955017, 0.32269683480262756, 0.3308989703655243, 0.3277674913406372, 0.31469982862472534, 0.33178186416625977, 0.31173378229141235, 0.3218460977077484, 0.3002118766307831, 0.3152843415737152, 0.31758391857147217]}\n"
     ]
    }
   ],
   "source": [
    "# the fit method returns a history object\n",
    "\n",
    "print(f\"Training parameters \\n {history.params}\") # training parameters\n",
    "print(f\"List of epochs \\n {history.epoch}\") #list of epochs\n",
    "print(f\"Dictionary of loss and extra metrics \\n {history.history}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# you can plot the learning curves\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "\n",
    "plt.title(\"Learning curves\")\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1) #set the vertical range to [0, -1]\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3352\n",
      "Test set performance: [0.33721521496772766, 0.8779000043869019]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on test set\n",
    "print(f\"Test set performance: {model.evaluate(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "Predicted probabilities\n",
      "[[0.   0.   0.   0.   0.   0.01 0.   0.03 0.   0.96]\n",
      " [0.   0.   0.99 0.   0.01 0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]]\n",
      "==============================\n",
      "Predicted class ['Ankle boot' 'Pullover' 'Trouser']\n",
      "Actual classes: ['Ankle boot' 'Pullover' 'Trouser']\n"
     ]
    }
   ],
   "source": [
    "# making predicitons for the first 3 itens in X_test\n",
    "\n",
    "X_predicitons = X_test[:3]\n",
    "y_proba = model.predict(X_predicitons)\n",
    "\n",
    "print(\"Predicted probabilities\")\n",
    "print(y_proba.round(2))\n",
    "\n",
    "print(\"===\" *10)\n",
    "\n",
    "# in newer versions of KEras, .predict_classes has been deprecated\n",
    "# use instead\n",
    "# np.argmax(y_proba, axis=1)\n",
    "\n",
    "print(f\"Predicted class {np.array(class_names)[np.argmax(y_proba, axis=1)]}\")\n",
    "print(f\"Actual classes: {np.array(class_names)[y_test[:3]]}\")\n",
    "\n",
    "#  this sample code uses a list and translate the values\n",
    "# np.array(class_names)[np.argmax(y_proba, axis=1)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first Keras sequential: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target\n",
    ")\n",
    "\n",
    "# split train into train and validation, with default 80/20 split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full\n",
    ")\n",
    "\n",
    "# scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_valid_scaled = scaler.transform(X_valid)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ANOTHER WAY FOR IMPLEMENTATION\n",
    "#tf.random.set_seed(42)\n",
    "#norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "#model = tf.keras.Sequential([\n",
    "#    norm_layer,\n",
    "#    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "#    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "#    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "#    tf.keras.layers.Dense(1)\n",
    "#])\n",
    "#optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "#model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "#norm_layer.adapt(X_train)\n",
    "#history = model.fit(X_train, y_train, epochs=20,\n",
    "#                    validation_data=(X_valid, y_valid))\n",
    "#mse_test, rmse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabi/codes/data_science/.venv/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 1.1085 - loss: 1.2941 - val_RootMeanSquaredError: 2.7544 - val_loss: 7.5868\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.8571 - loss: 0.7559 - val_RootMeanSquaredError: 0.7282 - val_loss: 0.5303\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6818 - loss: 0.4650 - val_RootMeanSquaredError: 0.7286 - val_loss: 0.5309\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6703 - loss: 0.4493 - val_RootMeanSquaredError: 0.6643 - val_loss: 0.4413\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6501 - loss: 0.4229 - val_RootMeanSquaredError: 0.6646 - val_loss: 0.4418\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6412 - loss: 0.4112 - val_RootMeanSquaredError: 0.6469 - val_loss: 0.4185\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6433 - loss: 0.4139 - val_RootMeanSquaredError: 0.6469 - val_loss: 0.4184\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6307 - loss: 0.3982 - val_RootMeanSquaredError: 0.6456 - val_loss: 0.4168\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6325 - loss: 0.4002 - val_RootMeanSquaredError: 0.6305 - val_loss: 0.3976\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6297 - loss: 0.3967 - val_RootMeanSquaredError: 0.6381 - val_loss: 0.4072\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6283 - loss: 0.3949 - val_RootMeanSquaredError: 0.6496 - val_loss: 0.4220\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6267 - loss: 0.3930 - val_RootMeanSquaredError: 0.6852 - val_loss: 0.4694\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6234 - loss: 0.3887 - val_RootMeanSquaredError: 0.6678 - val_loss: 0.4460\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6192 - loss: 0.3835 - val_RootMeanSquaredError: 0.7654 - val_loss: 0.5858\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6224 - loss: 0.3879 - val_RootMeanSquaredError: 0.7270 - val_loss: 0.5286\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6344 - loss: 0.4030 - val_RootMeanSquaredError: 0.6160 - val_loss: 0.3794\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6205 - loss: 0.3850 - val_RootMeanSquaredError: 0.6186 - val_loss: 0.3827\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6143 - loss: 0.3775 - val_RootMeanSquaredError: 0.6150 - val_loss: 0.3783\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6056 - loss: 0.3668 - val_RootMeanSquaredError: 0.6163 - val_loss: 0.3799\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.6044 - loss: 0.3655 - val_RootMeanSquaredError: 0.6094 - val_loss: 0.3714\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - RootMeanSquaredError: 0.6102 - loss: 0.3733\n",
      "MSE test [0.3598804473876953, 0.5999003648757935]\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "    keras.layers.Dense(30, activation=\"relu\", input_shape=X_train.shape[1:]),\n",
    "    keras.layers.Dense(1) # the last layer has only one output because it's the value we're trying to predict\n",
    "])\n",
    "\n",
    "model.compile(loss=\"mean_squared_error\", optimizer=\"sgd\", metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20,\n",
    "        validation_data= (X_valid_scaled, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f\"MSE test {mse_test}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabi/codes/data_science/.venv/lib/python3.10/site-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - RootMeanSquaredError: 1.1029 - loss: 1.2990 - val_RootMeanSquaredError: 0.6466 - val_loss: 0.4181\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6050 - loss: 0.3661 - val_RootMeanSquaredError: 0.6984 - val_loss: 0.4877\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5840 - loss: 0.3412 - val_RootMeanSquaredError: 0.6674 - val_loss: 0.4454\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5704 - loss: 0.3254 - val_RootMeanSquaredError: 0.7382 - val_loss: 0.5450\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5590 - loss: 0.3126 - val_RootMeanSquaredError: 0.8904 - val_loss: 0.7928\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5498 - loss: 0.3023 - val_RootMeanSquaredError: 0.7672 - val_loss: 0.5886\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5443 - loss: 0.2963 - val_RootMeanSquaredError: 0.7890 - val_loss: 0.6226\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5382 - loss: 0.2897 - val_RootMeanSquaredError: 1.0506 - val_loss: 1.1037\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5344 - loss: 0.2857 - val_RootMeanSquaredError: 1.3159 - val_loss: 1.7315\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5299 - loss: 0.2809 - val_RootMeanSquaredError: 1.6576 - val_loss: 2.7476\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5261 - loss: 0.2769 - val_RootMeanSquaredError: 2.0832 - val_loss: 4.3395\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5230 - loss: 0.2736 - val_RootMeanSquaredError: 2.4114 - val_loss: 5.8149\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5211 - loss: 0.2717 - val_RootMeanSquaredError: 2.4781 - val_loss: 6.1408\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5180 - loss: 0.2685 - val_RootMeanSquaredError: 2.3751 - val_loss: 5.6413\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5155 - loss: 0.2659 - val_RootMeanSquaredError: 2.6498 - val_loss: 7.0212\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5137 - loss: 0.2640 - val_RootMeanSquaredError: 2.5436 - val_loss: 6.4701\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5110 - loss: 0.2613 - val_RootMeanSquaredError: 2.5896 - val_loss: 6.7059\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5082 - loss: 0.2585 - val_RootMeanSquaredError: 2.5228 - val_loss: 6.3643\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5063 - loss: 0.2565 - val_RootMeanSquaredError: 1.8915 - val_loss: 3.5777\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5045 - loss: 0.2547 - val_RootMeanSquaredError: 2.1661 - val_loss: 4.6921\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5406 - loss: 0.2927  \n"
     ]
    }
   ],
   "source": [
    "# another way to implement the above\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "norm_layer = tf.keras.layers.Normalization(input_shape=X_train.shape[1:])\n",
    "model = tf.keras.Sequential([\n",
    "    norm_layer,\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(50, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(1)\n",
    "])\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "norm_layer.adapt(X_train)\n",
    "history = model.fit(X_train, y_train, epochs=20,\n",
    "                    validation_data=(X_valid, y_valid))\n",
    "mse_test, rmse_test = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a complex model\n",
    "\n",
    "It's possible to create a model where not all layers are connected to each other. This allows the model to deal with both simple and complex patterns better.\n",
    "\n",
    "<img src=\"../img/wide-and-deep-nn.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Normalization</span>)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">270</span> │ normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">930</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">38</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">39</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ normalization       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │         \u001b[38;5;34m17\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNormalization\u001b[0m)     │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m270\u001b[0m │ normalization[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)        │        \u001b[38;5;34m930\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m38\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ normalization[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m39\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,256</span> (4.91 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,256\u001b[0m (4.91 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,239</span> (4.84 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,239\u001b[0m (4.84 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (72.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m17\u001b[0m (72.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# example of wide and deep neural network\n",
    "\n",
    "# reset the name counters and make the code reproducible\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "normalisation_layer = tf.keras.layers.Normalization()\n",
    "\n",
    "hidden_layer_1 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "# an alternative way is to pass the input here with\n",
    "# hidden_layer_1 = tf.keras.layers.Dense(30, activation=\"relu\")(input)\n",
    "hidden_layer_2 = tf.keras.layers.Dense(30, activation=\"relu\")\n",
    "\n",
    "contact_layer = tf.keras.layers.Concatenate()\n",
    "output_layer = tf.keras.layers.Dense(1)\n",
    "\n",
    "## set the shape of the nn\n",
    "input_ = tf.keras.layers.Input(shape=X_train.shape[1:]) # first we need to create an input object, because we can have multiple inputs\n",
    "normalised = normalisation_layer(input_)\n",
    "hidden1 = hidden_layer_1(normalised)\n",
    "hidden2 = hidden_layer_2(hidden1)\n",
    "concat = contact_layer([normalised, hidden2])\n",
    "\n",
    "output = output_layer(concat)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_], outputs=[output])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabi/codes/data_science/.venv/lib/python3.10/site-packages/keras/src/models/functional.py:238: UserWarning: The structure of `inputs` doesn't match the expected structure.\n",
      "Expected: ['keras_tensor']\n",
      "Received: inputs=Tensor(shape=(None, 8))\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5351 - loss: 0.2864 - val_RootMeanSquaredError: 1.0447 - val_loss: 1.0913\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5325 - loss: 0.2836 - val_RootMeanSquaredError: 1.1219 - val_loss: 1.2586\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5313 - loss: 0.2823 - val_RootMeanSquaredError: 1.1820 - val_loss: 1.3972\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5303 - loss: 0.2812 - val_RootMeanSquaredError: 1.2455 - val_loss: 1.5512\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5292 - loss: 0.2802 - val_RootMeanSquaredError: 1.1448 - val_loss: 1.3105\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5286 - loss: 0.2795 - val_RootMeanSquaredError: 1.2763 - val_loss: 1.6290\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5276 - loss: 0.2784 - val_RootMeanSquaredError: 1.2443 - val_loss: 1.5484\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5265 - loss: 0.2773 - val_RootMeanSquaredError: 1.4523 - val_loss: 2.1093\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5257 - loss: 0.2764 - val_RootMeanSquaredError: 1.4495 - val_loss: 2.1012\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5252 - loss: 0.2759 - val_RootMeanSquaredError: 1.5280 - val_loss: 2.3347\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5240 - loss: 0.2746 - val_RootMeanSquaredError: 1.4586 - val_loss: 2.1274\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5235 - loss: 0.2741 - val_RootMeanSquaredError: 1.2724 - val_loss: 1.6190\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5230 - loss: 0.2736 - val_RootMeanSquaredError: 1.5334 - val_loss: 2.3512\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5225 - loss: 0.2731 - val_RootMeanSquaredError: 1.3816 - val_loss: 1.9087\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5217 - loss: 0.2722 - val_RootMeanSquaredError: 1.6604 - val_loss: 2.7570\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5205 - loss: 0.2710 - val_RootMeanSquaredError: 1.4007 - val_loss: 1.9618\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5200 - loss: 0.2705 - val_RootMeanSquaredError: 1.3090 - val_loss: 1.7134\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5194 - loss: 0.2698 - val_RootMeanSquaredError: 0.9236 - val_loss: 0.8530\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5189 - loss: 0.2693 - val_RootMeanSquaredError: 0.8519 - val_loss: 0.7258\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5202 - loss: 0.2707 - val_RootMeanSquaredError: 1.0206 - val_loss: 1.0416\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - RootMeanSquaredError: 0.5286 - loss: 0.2798\n",
      "[0.27730128169059753, 0.5265940427780151]\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "normalisation_layer.adapt(X_train)\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=20, \n",
    "            validation_data=(X_valid, y_valid))\n",
    "\n",
    "mse_test = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(mse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass only a subset of features through the wide path.\n",
    "\n",
    "<img src=\"../img/multiple_inputs.png\" width=\"30%\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 1.5307 - loss: 2.4702 - val_RootMeanSquaredError: 0.7186 - val_loss: 0.5164\n",
      "Epoch 2/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6786 - loss: 0.4607 - val_RootMeanSquaredError: 0.7124 - val_loss: 0.5076\n",
      "Epoch 3/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6347 - loss: 0.4029 - val_RootMeanSquaredError: 0.6798 - val_loss: 0.4622\n",
      "Epoch 4/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6191 - loss: 0.3833 - val_RootMeanSquaredError: 0.6256 - val_loss: 0.3913\n",
      "Epoch 5/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6087 - loss: 0.3706 - val_RootMeanSquaredError: 0.6373 - val_loss: 0.4062\n",
      "Epoch 6/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.6016 - loss: 0.3620 - val_RootMeanSquaredError: 0.8861 - val_loss: 0.7853\n",
      "Epoch 7/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5961 - loss: 0.3554 - val_RootMeanSquaredError: 1.2852 - val_loss: 1.6518\n",
      "Epoch 8/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5917 - loss: 0.3501 - val_RootMeanSquaredError: 0.9369 - val_loss: 0.8777\n",
      "Epoch 9/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5877 - loss: 0.3454 - val_RootMeanSquaredError: 1.1393 - val_loss: 1.2980\n",
      "Epoch 10/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5848 - loss: 0.3420 - val_RootMeanSquaredError: 1.1462 - val_loss: 1.3138\n",
      "Epoch 11/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5818 - loss: 0.3385 - val_RootMeanSquaredError: 0.9225 - val_loss: 0.8510\n",
      "Epoch 12/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5795 - loss: 0.3359 - val_RootMeanSquaredError: 1.0996 - val_loss: 1.2090\n",
      "Epoch 13/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5768 - loss: 0.3328 - val_RootMeanSquaredError: 1.2356 - val_loss: 1.5267\n",
      "Epoch 14/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5748 - loss: 0.3304 - val_RootMeanSquaredError: 1.7245 - val_loss: 2.9739\n",
      "Epoch 15/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5730 - loss: 0.3284 - val_RootMeanSquaredError: 1.9995 - val_loss: 3.9979\n",
      "Epoch 16/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5712 - loss: 0.3263 - val_RootMeanSquaredError: 3.1118 - val_loss: 9.6834\n",
      "Epoch 17/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5700 - loss: 0.3250 - val_RootMeanSquaredError: 4.1984 - val_loss: 17.6268\n",
      "Epoch 18/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5702 - loss: 0.3252 - val_RootMeanSquaredError: 2.4563 - val_loss: 6.0333\n",
      "Epoch 19/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5658 - loss: 0.3201 - val_RootMeanSquaredError: 2.0845 - val_loss: 4.3451\n",
      "Epoch 20/20\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5649 - loss: 0.3191 - val_RootMeanSquaredError: 2.5655 - val_loss: 6.5818\n",
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5731 - loss: 0.3290  \n",
      "\n",
      "\n",
      "MSE Test: [0.34250977635383606, 0.5852433443069458]\n"
     ]
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "input_A = tf.keras.layers.Input(shape=[5]) # pass 5 features as input A (in this case, it will be 0 to 4, speficified below), it will go through deep path\n",
    "input_B = tf.keras.layers.Input(shape=[6]) # pass 6 features as input B (in this case, it will be 2 to 7, speficified below), it will go thorugh wide path\n",
    "\n",
    "norm_layer_wide = tf.keras.layers.Normalization()\n",
    "norm_layer_deep = tf.keras.layers.Normalization()\n",
    "\n",
    "norm_wide = norm_layer_wide(input_A)\n",
    "norm_deep = norm_layer_deep(input_B)\n",
    "\n",
    "hidden1 = tf.keras.layers.Dense(30, activation=\"relu\")(norm_deep)\n",
    "hidden2 = tf.keras.layers.Dense(30, activation=\"relu\")(hidden1)\n",
    "concat = tf.keras.layers.concatenate([norm_wide, hidden2])\n",
    "\n",
    "output = tf.keras.layers.Dense(1)(concat)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=[input_A, input_B], outputs=[output])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3)\n",
    "model.compile(loss=\"mse\", optimizer=optimizer, metrics=[\"RootMeanSquaredError\"])\n",
    "\n",
    "# note you need to specifify the inputs A & B for all the sets\n",
    "X_train_A, X_train_B = X_train[:, :5], X_train[:, 2:]\n",
    "X_valid_A, X_valid_B = X_valid[:, :5], X_valid[:, 2:]\n",
    "X_test_A, X_test_B = X_test[:, :5], X_test[:, 2:]\n",
    "\n",
    "norm_layer_wide.adapt(X_train_A)\n",
    "norm_layer_deep.adapt(X_train_B)\n",
    "\n",
    "history = model.fit((X_train_A, X_train_B), y_train, epochs=20,\n",
    "                    validation_data=((X_valid_A, X_valid_B), y_valid))\n",
    "\n",
    "mse_test = model.evaluate((X_test_A, X_test_B), y_test)\n",
    "\n",
    "print(f\"\\n\\nMSE Test: {mse_test}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and restoring a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving a trained Keras model\n",
    "model.save(\"my_keras_model.keras\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - RootMeanSquaredError: 0.5731 - loss: 0.3290\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.34250977635383606, 0.5852433443069458]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the model\n",
    "loaded_model = tf.keras.models.load_model(\n",
    "    \"my_keras_model.keras\",\n",
    "    #custom_objects={\"WideAndDeepModel\": WideAndDeepModel} # if the model uses any custom_object, use it here\n",
    ")\n",
    "\n",
    "loaded_model.evaluate((X_test_A, X_test_B), y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Callbacks\n",
    "\n",
    "You can use callbacks so that keras will perform, for example, during the start of each training, at the end of ech epoch, and even before and after training each batch. This can be useful, for examplo, as a checkpoint in case your machine dies. You can also save the best model only, when you're using a validation set, by the use of callbacks (this is an easy way to implement early stopping).\n",
    "\n",
    "Another thing you can do regarding **early stopping\" is simply use .EarlyStopping with a large number of epochs. The model will stop training if the performance doesn't improve after a number of epochs and run back to the best performing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5634 - loss: 0.3175 - val_RootMeanSquaredError: 2.9200 - val_loss: 8.5264\n",
      "Epoch 2/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5643 - loss: 0.3185 - val_RootMeanSquaredError: 5.1238 - val_loss: 26.2537\n",
      "Epoch 3/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5653 - loss: 0.3197 - val_RootMeanSquaredError: 2.2452 - val_loss: 5.0408\n",
      "Epoch 4/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5602 - loss: 0.3138 - val_RootMeanSquaredError: 3.5219 - val_loss: 12.4038\n",
      "Epoch 5/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5607 - loss: 0.3144 - val_RootMeanSquaredError: 2.9561 - val_loss: 8.7385\n",
      "Epoch 6/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5597 - loss: 0.3134 - val_RootMeanSquaredError: 4.0569 - val_loss: 16.4586\n",
      "Epoch 7/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5575 - loss: 0.3109 - val_RootMeanSquaredError: 3.6450 - val_loss: 13.2861\n",
      "Epoch 8/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5564 - loss: 0.3096 - val_RootMeanSquaredError: 3.6202 - val_loss: 13.1056\n",
      "Epoch 9/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5550 - loss: 0.3081 - val_RootMeanSquaredError: 3.9609 - val_loss: 15.6888\n",
      "Epoch 10/10\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5553 - loss: 0.3084 - val_RootMeanSquaredError: 3.7785 - val_loss: 14.2770\n"
     ]
    }
   ],
   "source": [
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"my_checkpoints.weights.h5\",\n",
    "                                                   save_weights_only=True)\n",
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), (y_train), epochs=10,\n",
    "    validation_data=((X_valid_A, X_valid_B), (y_valid)),\n",
    "    callbacks=[checkpoint_cb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5538 - loss: 0.3067 - val_RootMeanSquaredError: 3.5171 - val_loss: 12.3697\n",
      "Epoch 2/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5519 - loss: 0.3046 - val_RootMeanSquaredError: 3.7372 - val_loss: 13.9667\n",
      "Epoch 3/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5517 - loss: 0.3044 - val_RootMeanSquaredError: 3.6580 - val_loss: 13.3810\n",
      "Epoch 4/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5511 - loss: 0.3037 - val_RootMeanSquaredError: 2.5621 - val_loss: 6.5643\n",
      "Epoch 5/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5490 - loss: 0.3015 - val_RootMeanSquaredError: 3.9352 - val_loss: 15.4855\n",
      "Epoch 6/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5492 - loss: 0.3017 - val_RootMeanSquaredError: 3.5409 - val_loss: 12.5381\n",
      "Epoch 7/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5501 - loss: 0.3026 - val_RootMeanSquaredError: 4.5860 - val_loss: 21.0311\n",
      "Epoch 8/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5485 - loss: 0.3009 - val_RootMeanSquaredError: 3.1455 - val_loss: 9.8940\n",
      "Epoch 9/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5463 - loss: 0.2985 - val_RootMeanSquaredError: 3.3232 - val_loss: 11.0436\n",
      "Epoch 10/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5454 - loss: 0.2975 - val_RootMeanSquaredError: 3.5266 - val_loss: 12.4372\n",
      "Epoch 11/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5449 - loss: 0.2970 - val_RootMeanSquaredError: 3.4370 - val_loss: 11.8129\n",
      "Epoch 12/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5456 - loss: 0.2977 - val_RootMeanSquaredError: 3.3549 - val_loss: 11.2552\n",
      "Epoch 13/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5437 - loss: 0.2957 - val_RootMeanSquaredError: 3.9456 - val_loss: 15.5674\n",
      "Epoch 14/100\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5434 - loss: 0.2953 - val_RootMeanSquaredError: 3.8918 - val_loss: 15.1459\n"
     ]
    }
   ],
   "source": [
    "# example of early stopping\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,  #determines how many epochs will run before early stopping\n",
    "                                                     restore_best_weights=True)\n",
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), (y_train), epochs=100,\n",
    "    validation_data=((X_valid_A, X_valid_B), (y_valid)),\n",
    "    callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation with TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set a root log directory for TensorBoard\n",
    "import os\n",
    "\n",
    "log_directory = os.path.join(os.curdir, \"tensorboard_logs\")\n",
    "\n",
    "def get_run_log_directory():\n",
    "    import time\n",
    "    run_id = time.strftime(\"run_%Y_%m_%d-%H_%M_%S\")\n",
    "    return os.path.join(log_directory, run_id)\n",
    "\n",
    "run_log_directory = get_run_log_directory()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5425 - loss: 0.2944 - val_RootMeanSquaredError: 3.9079 - val_loss: 15.2720\n",
      "Epoch 2/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5420 - loss: 0.2938 - val_RootMeanSquaredError: 3.3642 - val_loss: 11.3177\n",
      "Epoch 3/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5406 - loss: 0.2923 - val_RootMeanSquaredError: 3.4966 - val_loss: 12.2266\n",
      "Epoch 4/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5410 - loss: 0.2927 - val_RootMeanSquaredError: 3.2713 - val_loss: 10.7011\n",
      "Epoch 5/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5392 - loss: 0.2908 - val_RootMeanSquaredError: 4.1990 - val_loss: 17.6312\n",
      "Epoch 6/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5398 - loss: 0.2914 - val_RootMeanSquaredError: 4.9773 - val_loss: 24.7739\n",
      "Epoch 7/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5419 - loss: 0.2937 - val_RootMeanSquaredError: 3.8250 - val_loss: 14.6309\n",
      "Epoch 8/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5389 - loss: 0.2905 - val_RootMeanSquaredError: 3.2448 - val_loss: 10.5289\n",
      "Epoch 9/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5376 - loss: 0.2891 - val_RootMeanSquaredError: 3.8195 - val_loss: 14.5882\n",
      "Epoch 10/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5382 - loss: 0.2897 - val_RootMeanSquaredError: 3.3675 - val_loss: 11.3399\n",
      "Epoch 11/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5372 - loss: 0.2886 - val_RootMeanSquaredError: 4.9215 - val_loss: 24.2210\n",
      "Epoch 12/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5380 - loss: 0.2895 - val_RootMeanSquaredError: 4.5407 - val_loss: 20.6182\n",
      "Epoch 13/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5370 - loss: 0.2884 - val_RootMeanSquaredError: 3.6205 - val_loss: 13.1078\n",
      "Epoch 14/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5353 - loss: 0.2866 - val_RootMeanSquaredError: 3.5591 - val_loss: 12.6669\n",
      "Epoch 15/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5348 - loss: 0.2861 - val_RootMeanSquaredError: 3.0163 - val_loss: 9.0981\n",
      "Epoch 16/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5346 - loss: 0.2859 - val_RootMeanSquaredError: 3.6259 - val_loss: 13.1472\n",
      "Epoch 17/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5367 - loss: 0.2881 - val_RootMeanSquaredError: 3.2891 - val_loss: 10.8184\n",
      "Epoch 18/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5361 - loss: 0.2874 - val_RootMeanSquaredError: 4.0840 - val_loss: 16.6788\n",
      "Epoch 19/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5329 - loss: 0.2840 - val_RootMeanSquaredError: 4.4074 - val_loss: 19.4251\n",
      "Epoch 20/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5343 - loss: 0.2855 - val_RootMeanSquaredError: 3.8695 - val_loss: 14.9732\n",
      "Epoch 21/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5332 - loss: 0.2844 - val_RootMeanSquaredError: 3.5279 - val_loss: 12.4457\n",
      "Epoch 22/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5317 - loss: 0.2828 - val_RootMeanSquaredError: 4.1030 - val_loss: 16.8344\n",
      "Epoch 23/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5329 - loss: 0.2841 - val_RootMeanSquaredError: 3.9373 - val_loss: 15.5020\n",
      "Epoch 24/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5323 - loss: 0.2834 - val_RootMeanSquaredError: 3.7769 - val_loss: 14.2653\n",
      "Epoch 25/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5313 - loss: 0.2823 - val_RootMeanSquaredError: 3.7214 - val_loss: 13.8491\n",
      "Epoch 26/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5318 - loss: 0.2829 - val_RootMeanSquaredError: 4.3229 - val_loss: 18.6873\n",
      "Epoch 27/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5317 - loss: 0.2828 - val_RootMeanSquaredError: 4.0743 - val_loss: 16.6002\n",
      "Epoch 28/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5303 - loss: 0.2813 - val_RootMeanSquaredError: 3.8906 - val_loss: 15.1371\n",
      "Epoch 29/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5311 - loss: 0.2822 - val_RootMeanSquaredError: 3.4600 - val_loss: 11.9719\n",
      "Epoch 30/30\n",
      "\u001b[1m363/363\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - RootMeanSquaredError: 0.5290 - loss: 0.2799 - val_RootMeanSquaredError: 3.8963 - val_loss: 15.1808\n"
     ]
    }
   ],
   "source": [
    "# with Keras callback you can save your logs easily\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(run_log_directory)\n",
    "\n",
    "history = model.fit(\n",
    "    (X_train_A, X_train_B), (y_train), epochs=30,\n",
    "    validation_data=((X_valid_A, X_valid_B), (y_valid)),\n",
    "    callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the board:\n",
    "\n",
    "1. Activate the virtual machine\n",
    "    source .venv/bin/activate\n",
    "2. Run this (don't forget to update the log directory)\n",
    "    tensorboard --logdir=./my_logs --port=6006 \n",
    "3. TensorBoard 2.0.0 at http://mycomputer.local:6006 (press Ctrl+C to quit)\n",
    "\n",
    "You will be able to access via localhost:6006\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General notes\n",
    "\n",
    "-- In most cases, you can start with one or two hidden layers and it will work fine.\n",
    "-- For more complex problems you can incrementally increase the number of hidden layers until you achieve overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting Increasing Loss in Neural Network Training\n",
    "\n",
    "Potential Causes and Solutions:\n",
    "\n",
    "### Learning Rate\n",
    "\n",
    "- **Issue**: Too high a learning rate can cause the model to overshoot the optimal solution.\n",
    "- **Solution**: Reduce the learning rate.\n",
    "\n",
    "### Vanishing or Exploding Gradients\n",
    "\n",
    "- **Issue**: Gradients become too small or too large.\n",
    "- **Solution**: Use techniques like gradient clipping, normalization, or appropriate activation functions (e.g., ReLU).\n",
    "\n",
    "### Overfitting\n",
    "\n",
    "- **Issue**: The model memorizes the training data instead of generalizing.\n",
    "- **Solution**: Use regularization techniques (L1/L2 regularization, dropout), gather more data, or simplify the model.\n",
    "\n",
    "### Poor Initialization\n",
    "\n",
    "- **Issue**: Initial weights and biases are not optimal.\n",
    "- **Solution**: Use techniques like Xavier or He initialization.\n",
    "\n",
    "### Data Issues\n",
    "\n",
    "- **Issue**: Noisy or incorrect data.\n",
    "- **Solution**: Clean and preprocess the data, and consider data augmentation.\n",
    "\n",
    "### Implementation Errors\n",
    "\n",
    "- **Issue**: Bugs in the code.\n",
    "- **Solution**: Thoroughly review and debug the code.\n",
    "\n",
    " **Troubleshooting Tips:**\n",
    "\n",
    "- **Monitor Metrics**: Track loss, accuracy, and other relevant metrics.\n",
    "- **Visualize Learning Curves**: Plot training and validation loss to identify trends.\n",
    "- **Experiment with Hyperparameters**: Adjust learning rate, batch size, optimizer, etc.\n",
    "- **Try Different Architectures**: Explore different network architectures.\n",
    "- **Save Model Checkpoints**: Allow for reverting to previous states.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
