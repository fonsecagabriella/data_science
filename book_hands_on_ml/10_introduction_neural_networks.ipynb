{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction the NN\n",
    "\n",
    "In essence: For each epoch, for each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error con‐ tribution from each connection (reverse pass), and finally slightly tweaks the connec‐ tion weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "\n",
    "<img src=\"../img/derivatives_activation.png\" width=\"80%\">\n",
    "\n",
    "*Derivatives: rate of change*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression MLPs\n",
    "\n",
    "| Hyperparameter        | Typical Value                                                                 |\n",
    "|-----------------------|------------------------------------------------------------------------------|\n",
    "| # input neurons       | One per input feature (e.g., 28 x 28 = 784 for MNIST)                       |\n",
    "| # hidden layers       | Depends on the problem. Typically 1 to 5.                                   |\n",
    "| # neurons per hidden layer | Depends on the problem. Typically 10 to 100.                            |\n",
    "| # output neurons      | 1 per prediction dimension (if you expect 2 values, then 2 outputs)                                                  |\n",
    "| Hidden activation     | ReLU (or SELU)                                              |\n",
    "| Output activation     | None or ReLU/Softplus (if positive outputs) or Logistic (0 to 1)/Tanh (hyperbolic tangent)(-1 to 1) (if bounded outputs) |\n",
    "| Loss function         | MSE or MAE/Huber (if outliers)                                              |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
