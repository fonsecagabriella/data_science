{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction the NN\n",
    "\n",
    "In essence: For each epoch, for each training instance the backpropagation algorithm first makes a prediction (forward pass), measures the error, then goes through each layer in reverse to measure the error contribution from each connection (reverse pass), and finally slightly tweaks the connection weights to reduce the error (Gradient Descent step).\n",
    "\n",
    "\n",
    "<img src=\"../img/derivatives_activation.png\" width=\"80%\">\n",
    "\n",
    "*Derivatives: rate of change*\n",
    "\n",
    "\n",
    "**Key Differences Between Perceptron and Neuron**\n",
    "| Feature               | Perceptron                       | Neuron in MLP                   |\n",
    "|-----------------------|-----------------------------------|----------------------------------|\n",
    "| **Activation Function** | Step function                   | Nonlinear (e.g., ReLU, sigmoid) |\n",
    "| **Output**            | Binary (0 or 1)                  | Continuous or nonlinear values  |\n",
    "| **Usage**             | Single-layer models (linear tasks) | Multilayer networks (nonlinear tasks) |\n",
    "| **Problem Solving**   | Only linear separability         | Handles nonlinear problems      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regression MLPs**\n",
    "\n",
    "| Hyperparameter        | Typical Value                                                                 |\n",
    "|-----------------------|------------------------------------------------------------------------------|\n",
    "| # input neurons       | One per input feature (e.g., 28 x 28 = 784 for MNIST)                       |\n",
    "| # hidden layers       | Depends on the problem. Typically 1 to 5.                                   |\n",
    "| # neurons per hidden layer | Depends on the problem. Typically 10 to 100.                            |\n",
    "| # output neurons      | 1 per prediction dimension (if you expect 2 values, then 2 outputs)                                                  |\n",
    "| Hidden activation     | ReLU (or SELU)                                              |\n",
    "| Output activation     | None or ReLU/Softplus (if positive outputs) or Logistic (0 to 1)/Tanh (hyperbolic tangent)(-1 to 1) (if bounded outputs) |\n",
    "| Loss function         | MSE or MAE/Huber (if outliers)                                              |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "housing = fetch_california_housing()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    housing.data, housing.target, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, random_state=42)\n",
    "\n",
    "mlp_reg = MLPRegressor(hidden_layer_sizes=[50, 50, 50], random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_reg)\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_valid)\n",
    "rmse = mean_squared_error(y_valid, y_pred, squared=False)\n",
    "\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Classification MLPs**\n",
    "\n",
    "| Hyperparameter            | Binary classification | Multilabel binary classification | Multiclass classification |\n",
    "|---------------------------|-----------------------|-----------------------------------|---------------------------|\n",
    "| Input and hidden layers   | Same as regression   | Same as regression               | Same as regression       |\n",
    "| # output neurons          | 1                   | 1 per label                      | 1 per class              |\n",
    "| Output layer activation   | Logistic            | Logistic                          | Softmax                  |\n",
    "| Loss functino   | Cross-entropy            | Cross-entropy                         | Cross-entropy                  |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "iris = load_iris()\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    iris.data, iris.target, test_size=0.1, random_state=42)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=0.1, random_state=42)\n",
    "\n",
    "mlp_clf = MLPClassifier(hidden_layer_sizes=[5], max_iter=10_000,\n",
    "                        random_state=42)\n",
    "pipeline = make_pipeline(StandardScaler(), mlp_clf)\n",
    "pipeline.fit(X_train, y_train)\n",
    "accuracy = pipeline.score(X_valid, y_valid)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Simple image classifier with Keras**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__\n",
    "keras.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images shape: (60000, 28, 28)\n",
      "Train labels shape: (60000,)\n",
      "Test images shape: (10000, 28, 28)\n",
      "Test labels shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# the fashion ds has 10 categories, like mnist, but with clothes\n",
    "\n",
    "def load_idx(filepath):\n",
    "    \"\"\"Load IDX format data from a gzip file.\"\"\"\n",
    "    with gzip.open(filepath, 'rb') as f:\n",
    "        # Read the file content\n",
    "        data = f.read()\n",
    "        # Magic number (first 4 bytes)\n",
    "        magic = int.from_bytes(data[0:4], byteorder='big')\n",
    "        # Number of items (next 4 bytes)\n",
    "        num_items = int.from_bytes(data[4:8], byteorder='big')\n",
    "        if magic == 2049:  # Labels\n",
    "            return np.frombuffer(data[8:], dtype=np.uint8)\n",
    "        elif magic == 2051:  # Images\n",
    "            rows = int.from_bytes(data[8:12], byteorder='big')\n",
    "            cols = int.from_bytes(data[12:16], byteorder='big')\n",
    "            images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "            return images.reshape(num_items, rows, cols)\n",
    "        else:\n",
    "            raise ValueError(\"Unknown magic number in file header!\")\n",
    "\n",
    "# Paths to the data files\n",
    "train_images_path = '../data/train-images-idx3-ubyte.gz'\n",
    "train_labels_path = '../data/train-labels-idx1-ubyte.gz'\n",
    "test_images_path = '../data/t10k-images-idx3-ubyte.gz'\n",
    "test_labels_path = '../data/t10k-labels-idx1-ubyte.gz'\n",
    "\n",
    "# Load the data\n",
    "X_train_full = load_idx(train_images_path)\n",
    "y_train_full = load_idx(train_labels_path)\n",
    "X_test = load_idx(test_images_path)\n",
    "y_test = load_idx(test_labels_path)\n",
    "\n",
    "# Normalize the image data\n",
    "# we also need to scale the data, for simplicity we will scale the pixel intensities in the 0-1 range simply dividing them by 255\n",
    "\n",
    "X_train_full = X_train_full / 255.0\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "print(\"Train images shape:\", X_train_full.shape)\n",
    "print(\"Train labels shape:\", y_train_full.shape)\n",
    "print(\"Test images shape:\", X_test.shape)\n",
    "print(\"Test labels shape:\", y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we will create a validation set\n",
    "\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class names\n",
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample of class for a given item\n",
    "class_names[y_train[10]]\n",
    "\n",
    "#y_train[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My first Keras sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gabi/codes/data_science/.venv/lib/python3.12/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential([\n",
    "\n",
    "    keras.layers.Flatten(input_shape=[28,28]), # receives input data and converts it to 1d array\n",
    "    keras.layers.Dense(300, activation=\"relu\"), # dense layer with 300 neurons\n",
    "    keras.layers.Dense(100, activation=\"relu\"), # second dense layer with 100 neurons\n",
    "    keras.layers.Dense(10, activation=\"softmax\") #output layer, with 10 nodes, as 10 classes, softmax because multiclass\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">235,500</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │       \u001b[38;5;34m235,500\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">266,610</span> (1.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m266,610\u001b[0m (1.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get info about the model including output shape of each layer and the number of parameters\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Flatten name=flatten, built=True>,\n",
       " <Dense name=dense, built=True>,\n",
       " <Dense name=dense_1, built=True>,\n",
       " <Dense name=dense_2, built=True>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all the layers of a model\n",
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can call each layer by its index\n",
    "model.layers[1].name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dense_2'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can het the layer by its name\n",
    "model.get_layer(\"dense_2\").name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02308173,  0.02321342,  0.01780492, ..., -0.01716774,\n",
       "         0.01247725,  0.0568724 ],\n",
       "       [ 0.05130477,  0.04607778, -0.04728509, ...,  0.00962491,\n",
       "        -0.01858232,  0.03471071],\n",
       "       [ 0.02859914, -0.06492709,  0.02310194, ..., -0.02200221,\n",
       "        -0.07220224, -0.0112334 ],\n",
       "       ...,\n",
       "       [-0.07249278,  0.02996396,  0.02114277, ...,  0.05384013,\n",
       "        -0.03104062, -0.02192979],\n",
       "       [-0.02263604,  0.06190917,  0.00712591, ...,  0.02354175,\n",
       "        -0.00246117, -0.00628362],\n",
       "       [ 0.02515146,  0.02241144, -0.04031318, ..., -0.07111613,\n",
       "        -0.07353047,  0.05182727]], dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you can get all the weights and biases from each layer\n",
    "weights, biases = model.layers[1].get_weights()\n",
    "\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) for `plot_model` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
