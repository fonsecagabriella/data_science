{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST with Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-12 15:34:22.677082: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# separate X_train_full into train and validation sets\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X_train_full, y_train_full, test_size=0.2, random_state=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (48000, 28, 28) \n",
      " X_validation: (12000, 28, 28) \n",
      " X_test: (10000, 28, 28)\n",
      "y_train: (48000,) \n",
      " y_validation: [9 7 8 ... 3 7 4] \n",
      " y_test: (10000,)\n"
     ]
    }
   ],
   "source": [
    "# check the shapes for X_train, X_validation, X_test\n",
    "\n",
    "print(f\"X_train: {X_train.shape} \\n X_validation: {X_validation.shape} \\n X_test: {X_test.shape}\")\n",
    "print(f\"y_train: {y_train.shape} \\n y_validation: {y_validation} \\n y_test: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/GU6VOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAIaklEQVR4nO3cO2tW2xqG4TnFwlOKRBRSCGksPKCgCKZQooVgoZAitZaWYirBykKMRLDyNwhWSoiIBg8gKCIogn8hCEKEINFqrmbzNGvttXnnjvlicl39wxzIJ3dGM9qu67oGAJqm2TLoAwCwfogCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQGwd9AHgd/j161d5s7S09BtO8nevXr3qtfvw4UN58/79+/Jm586d5c38/Hx5Mz09Xd40TdNcvHixvDl16lSvb21GbgoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIA0XZd1w36EPBv+jwEd/369fJmYWGhvOmj73+5tm1X+SSD1fffYXh4uLzp8wjh4cOHy5uNwE0BgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAILYO+gDwvzx+/Li8WavH7dbS0NBQeTM+Pl7eHDhwoLw5f/58ebOWRkdHB32EP4abAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAEC0Xdd1gz4E/JtPnz6VN8eOHfsNJ/m7mZmZ8ubcuXO9vrV9+/byZv/+/b2+xeblpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAbB30Adg85ufne+0uX768ugf5LxYWFsqb06dPlzdbtvhbjPXLrxOAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgPIjHmnnx4kWv3bdv31b5JP9sZGSkvPG4HRuNXzQAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAeBCPNfPkyZNeu7ZtV/kkg/0OrGduCgCEKAAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgDhQTx6mZ2dLW++fPnS61t9Hqo7fvx4eTM2NlbewEbjpgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAtF3XdYM+BH+e0dHR8ubr16+9vrV79+7y5uHDh+XNxMREeQMbjZsCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQGwd9AH4M504caK8mZub6/Wtbdu2lTdjY2O9vgWbnZsCACEKAIQoABCiAECIAgAhCgCEKAAQogBAiAIAIQoAhCgAEKIAQLRd13WDPgSbw4ULF3rtFhYWypufP3+WNzMzM+XNlStXypuhoaHyBtaKmwIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQogBAeBCPdW96erq8uXfv3uof5B8cPHiwvOnzwF/TNM3evXt77aDCTQGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgPIjHure8vFzevH37try5fft2efPy5cvy5siRI+VN0zTN/fv3y5vx8fFe32LzclMAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAILySCv+xtLRU3ty6dau8uXv3bnnTNE2zY8eO8ub58+flzcmTJ8sbNg43BQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDwIB78H378+FHeDA0N9fpW27blzdGjR8ubp0+fljd79uwpb1if3BQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAYuugD8DgvX79uryZm5srb+7cuVPerKWVlZXyZmpqqrxZyzcoP378WN4sLi6WNx7E2zjcFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQDCg3gbzOfPn8ubycnJ8ub79+/lzcTERHnTNE1z5syZ8ubZs2flzezsbHnz5s2b8qZt2/Km7+7s2bPlzb59+8obNg43BQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYDwIN4Gs7i4WN70edyuj2vXrvXajYyMlDfv3r3r9a31rM/jdg8ePChvhoeHyxs2DjcFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAKLtuq4b9CFYPcvLy+XNpUuXyptHjx6VN31/am3b9tqthUOHDpU3V69e7fWtycnJ8saLp1S5KQAQogBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEB/FoVlZWypuZmZny5ubNm+VN0/R7EG9qaqq8uXHjRnkzNjZW3uzatau8gbXipgBAiAIAIQoAhCgAEKIAQIgCACEKAIQoABCiAECIAgAhCgCEKAAQHsQDINwUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACBEAYAQBQBCFAAIUQAgRAGAEAUAQhQACFEAIEQBgBAFAEIUAAhRACD+AgrQ6UGTO9TWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a few digits\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X_train[45], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.5129 - loss: 1.6373 - val_accuracy: 0.8461 - val_loss: 0.6173\n",
      "Epoch 2/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8580 - loss: 0.5435 - val_accuracy: 0.8869 - val_loss: 0.4265\n",
      "Epoch 3/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8927 - loss: 0.3939 - val_accuracy: 0.9043 - val_loss: 0.3587\n",
      "Epoch 4/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9068 - loss: 0.3332 - val_accuracy: 0.9129 - val_loss: 0.3222\n",
      "Epoch 5/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9164 - loss: 0.2978 - val_accuracy: 0.9187 - val_loss: 0.2982\n",
      "Epoch 6/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9231 - loss: 0.2731 - val_accuracy: 0.9222 - val_loss: 0.2806\n",
      "Epoch 7/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.2543 - val_accuracy: 0.9264 - val_loss: 0.2668\n",
      "Epoch 8/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9315 - loss: 0.2390 - val_accuracy: 0.9286 - val_loss: 0.2554\n",
      "Epoch 9/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9349 - loss: 0.2263 - val_accuracy: 0.9312 - val_loss: 0.2458\n",
      "Epoch 10/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9384 - loss: 0.2152 - val_accuracy: 0.9328 - val_loss: 0.2375\n",
      "Epoch 11/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9412 - loss: 0.2056 - val_accuracy: 0.9353 - val_loss: 0.2302\n",
      "Epoch 12/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9438 - loss: 0.1970 - val_accuracy: 0.9369 - val_loss: 0.2237\n",
      "Epoch 13/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9460 - loss: 0.1893 - val_accuracy: 0.9394 - val_loss: 0.2178\n",
      "Epoch 14/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9482 - loss: 0.1822 - val_accuracy: 0.9408 - val_loss: 0.2126\n",
      "Epoch 15/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9500 - loss: 0.1758 - val_accuracy: 0.9420 - val_loss: 0.2078\n",
      "Epoch 16/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9517 - loss: 0.1699 - val_accuracy: 0.9430 - val_loss: 0.2033\n",
      "Epoch 17/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9531 - loss: 0.1644 - val_accuracy: 0.9441 - val_loss: 0.1993\n",
      "Epoch 18/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 8ms/step - accuracy: 0.9551 - loss: 0.1592 - val_accuracy: 0.9451 - val_loss: 0.1955\n",
      "Epoch 19/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9567 - loss: 0.1545 - val_accuracy: 0.9462 - val_loss: 0.1921\n",
      "Epoch 20/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9580 - loss: 0.1500 - val_accuracy: 0.9472 - val_loss: 0.1888\n",
      "Epoch 21/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9590 - loss: 0.1458 - val_accuracy: 0.9482 - val_loss: 0.1858\n",
      "Epoch 22/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.1418 - val_accuracy: 0.9490 - val_loss: 0.1830\n",
      "Epoch 23/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9610 - loss: 0.1381 - val_accuracy: 0.9496 - val_loss: 0.1803\n",
      "Epoch 24/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9621 - loss: 0.1346 - val_accuracy: 0.9503 - val_loss: 0.1778\n",
      "Epoch 25/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9632 - loss: 0.1312 - val_accuracy: 0.9517 - val_loss: 0.1754\n",
      "Epoch 26/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9639 - loss: 0.1280 - val_accuracy: 0.9524 - val_loss: 0.1732\n",
      "Epoch 27/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.1249 - val_accuracy: 0.9534 - val_loss: 0.1710\n",
      "Epoch 28/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9655 - loss: 0.1220 - val_accuracy: 0.9540 - val_loss: 0.1690\n",
      "Epoch 29/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.1192 - val_accuracy: 0.9550 - val_loss: 0.1671\n",
      "Epoch 30/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.1165 - val_accuracy: 0.9557 - val_loss: 0.1652\n",
      "Epoch 31/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9680 - loss: 0.1140 - val_accuracy: 0.9565 - val_loss: 0.1634\n",
      "Epoch 32/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9689 - loss: 0.1115 - val_accuracy: 0.9571 - val_loss: 0.1617\n",
      "Epoch 33/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9699 - loss: 0.1091 - val_accuracy: 0.9575 - val_loss: 0.1601\n",
      "Epoch 34/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9705 - loss: 0.1068 - val_accuracy: 0.9580 - val_loss: 0.1585\n",
      "Epoch 35/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9714 - loss: 0.1046 - val_accuracy: 0.9582 - val_loss: 0.1570\n",
      "Epoch 36/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9718 - loss: 0.1024 - val_accuracy: 0.9586 - val_loss: 0.1556\n",
      "Epoch 37/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9723 - loss: 0.1003 - val_accuracy: 0.9590 - val_loss: 0.1543\n",
      "Epoch 38/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9727 - loss: 0.0983 - val_accuracy: 0.9596 - val_loss: 0.1529\n",
      "Epoch 39/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9732 - loss: 0.0964 - val_accuracy: 0.9597 - val_loss: 0.1517\n",
      "Epoch 40/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9740 - loss: 0.0945 - val_accuracy: 0.9603 - val_loss: 0.1505\n",
      "Epoch 41/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9747 - loss: 0.0926 - val_accuracy: 0.9604 - val_loss: 0.1493\n",
      "Epoch 42/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9753 - loss: 0.0909 - val_accuracy: 0.9613 - val_loss: 0.1482\n",
      "Epoch 43/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9759 - loss: 0.0891 - val_accuracy: 0.9617 - val_loss: 0.1471\n",
      "Epoch 44/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9764 - loss: 0.0874 - val_accuracy: 0.9622 - val_loss: 0.1460\n",
      "Epoch 45/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0858 - val_accuracy: 0.9626 - val_loss: 0.1450\n",
      "Epoch 46/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9776 - loss: 0.0842 - val_accuracy: 0.9626 - val_loss: 0.1440\n",
      "Epoch 47/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9780 - loss: 0.0827 - val_accuracy: 0.9627 - val_loss: 0.1431\n",
      "Epoch 48/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9784 - loss: 0.0812 - val_accuracy: 0.9629 - val_loss: 0.1422\n",
      "Epoch 49/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9788 - loss: 0.0797 - val_accuracy: 0.9636 - val_loss: 0.1413\n",
      "Epoch 50/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0783 - val_accuracy: 0.9638 - val_loss: 0.1405\n",
      "Epoch 51/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9796 - loss: 0.0769 - val_accuracy: 0.9640 - val_loss: 0.1397\n",
      "Epoch 52/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9799 - loss: 0.0755 - val_accuracy: 0.9644 - val_loss: 0.1389\n",
      "Epoch 53/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9805 - loss: 0.0742 - val_accuracy: 0.9645 - val_loss: 0.1382\n",
      "Epoch 54/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9807 - loss: 0.0729 - val_accuracy: 0.9646 - val_loss: 0.1375\n",
      "Epoch 55/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9812 - loss: 0.0717 - val_accuracy: 0.9647 - val_loss: 0.1368\n",
      "Epoch 56/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9816 - loss: 0.0704 - val_accuracy: 0.9648 - val_loss: 0.1361\n",
      "Epoch 57/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9820 - loss: 0.0692 - val_accuracy: 0.9651 - val_loss: 0.1354\n",
      "Epoch 58/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0681 - val_accuracy: 0.9649 - val_loss: 0.1348\n",
      "Epoch 59/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0669 - val_accuracy: 0.9650 - val_loss: 0.1342\n",
      "Epoch 60/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9828 - loss: 0.0658 - val_accuracy: 0.9654 - val_loss: 0.1336\n",
      "Epoch 61/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0647 - val_accuracy: 0.9655 - val_loss: 0.1331\n",
      "Epoch 62/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0636 - val_accuracy: 0.9657 - val_loss: 0.1325\n",
      "Epoch 63/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0625 - val_accuracy: 0.9659 - val_loss: 0.1320\n",
      "Epoch 64/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9849 - loss: 0.0615 - val_accuracy: 0.9662 - val_loss: 0.1314\n",
      "Epoch 65/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9852 - loss: 0.0605 - val_accuracy: 0.9663 - val_loss: 0.1309\n",
      "Epoch 66/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9855 - loss: 0.0595 - val_accuracy: 0.9665 - val_loss: 0.1305\n",
      "Epoch 67/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9856 - loss: 0.0585 - val_accuracy: 0.9668 - val_loss: 0.1300\n",
      "Epoch 68/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9859 - loss: 0.0576 - val_accuracy: 0.9672 - val_loss: 0.1295\n",
      "Epoch 69/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9863 - loss: 0.0566 - val_accuracy: 0.9672 - val_loss: 0.1291\n",
      "Epoch 70/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9864 - loss: 0.0557 - val_accuracy: 0.9674 - val_loss: 0.1287\n",
      "Epoch 71/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0548 - val_accuracy: 0.9677 - val_loss: 0.1283\n",
      "Epoch 72/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9869 - loss: 0.0539 - val_accuracy: 0.9678 - val_loss: 0.1279\n",
      "Epoch 73/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9872 - loss: 0.0531 - val_accuracy: 0.9678 - val_loss: 0.1275\n",
      "Epoch 74/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9875 - loss: 0.0522 - val_accuracy: 0.9679 - val_loss: 0.1272\n",
      "Epoch 75/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9876 - loss: 0.0514 - val_accuracy: 0.9680 - val_loss: 0.1268\n",
      "Epoch 76/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9878 - loss: 0.0506 - val_accuracy: 0.9680 - val_loss: 0.1265\n",
      "Epoch 77/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.0498 - val_accuracy: 0.9682 - val_loss: 0.1261\n",
      "Epoch 78/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9882 - loss: 0.0490 - val_accuracy: 0.9682 - val_loss: 0.1258\n",
      "Epoch 79/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 6ms/step - accuracy: 0.9885 - loss: 0.0483 - val_accuracy: 0.9683 - val_loss: 0.1255\n",
      "Epoch 80/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9887 - loss: 0.0476 - val_accuracy: 0.9683 - val_loss: 0.1252\n",
      "Epoch 81/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9889 - loss: 0.0468 - val_accuracy: 0.9683 - val_loss: 0.1250\n",
      "Epoch 82/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0461 - val_accuracy: 0.9684 - val_loss: 0.1247\n",
      "Epoch 83/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9894 - loss: 0.0454 - val_accuracy: 0.9682 - val_loss: 0.1244\n",
      "Epoch 84/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9898 - loss: 0.0447 - val_accuracy: 0.9684 - val_loss: 0.1242\n",
      "Epoch 85/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0441 - val_accuracy: 0.9684 - val_loss: 0.1239\n",
      "Epoch 86/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 6ms/step - accuracy: 0.9901 - loss: 0.0434 - val_accuracy: 0.9684 - val_loss: 0.1237\n",
      "Epoch 87/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9903 - loss: 0.0428 - val_accuracy: 0.9686 - val_loss: 0.1235\n",
      "Epoch 88/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9907 - loss: 0.0421 - val_accuracy: 0.9686 - val_loss: 0.1233\n",
      "Epoch 89/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0415 - val_accuracy: 0.9686 - val_loss: 0.1231\n",
      "Epoch 90/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9910 - loss: 0.0409 - val_accuracy: 0.9686 - val_loss: 0.1229\n",
      "Epoch 91/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9911 - loss: 0.0403 - val_accuracy: 0.9687 - val_loss: 0.1227\n",
      "Epoch 92/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0397 - val_accuracy: 0.9687 - val_loss: 0.1225\n",
      "Epoch 93/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0391 - val_accuracy: 0.9687 - val_loss: 0.1223\n",
      "Epoch 94/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9919 - loss: 0.0386 - val_accuracy: 0.9688 - val_loss: 0.1222\n",
      "Epoch 95/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0380 - val_accuracy: 0.9689 - val_loss: 0.1220\n",
      "Epoch 96/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9921 - loss: 0.0375 - val_accuracy: 0.9690 - val_loss: 0.1219\n",
      "Epoch 97/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9923 - loss: 0.0369 - val_accuracy: 0.9690 - val_loss: 0.1217\n",
      "Epoch 98/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.0364 - val_accuracy: 0.9691 - val_loss: 0.1216\n",
      "Epoch 99/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0359 - val_accuracy: 0.9691 - val_loss: 0.1214\n",
      "Epoch 100/100\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9925 - loss: 0.0354 - val_accuracy: 0.9692 - val_loss: 0.1213\n"
     ]
    }
   ],
   "source": [
    "# Create a normalisation layer\n",
    "normalisation_layer = tf.keras.layers.Normalization(axis=-1)\n",
    "normalisation_layer.adapt(X_train)  # Compute the mean and variance from the training data\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    normalisation_layer,\n",
    "    tf.keras.layers.Flatten(input_shape=[28,28]), # receives input data and converts it to 1d array\n",
    "    tf.keras.layers.Dense(300, activation=\"relu\"), # dense layer with 300 neurons\n",
    "    tf.keras.layers.Dense(100, activation=\"relu\"), # second dense layer with 100 neurons\n",
    "    tf.keras.layers.Dense(10, activation=\"softmax\") #output layer, with 10 nodes, as 10 classes, softmax because multiclass\n",
    "])\n",
    "\n",
    "# implement early stopping\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,  #determines how many epochs will run before early stopping\n",
    "                                                     restore_best_weights=True)\n",
    "\n",
    "# implement TensorBoard\n",
    "tensorboard_cb = tf.keras.callbacks.TensorBoard(\"mnist_board\")\n",
    "\n",
    "# implement checkpoint to keep only the best model\n",
    "checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"mnist_model.keras\", save_best_only=True)\n",
    "\n",
    "\n",
    "#implement optmiser\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\n",
    "\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "                optimizer=optimizer,\n",
    "                metrics=[\"accuracy\"])\n",
    "\n",
    "history = model.fit(X_train,y_train, \n",
    "    validation_data=(X_validation, y_validation), epochs=100,\n",
    "    callbacks=[early_stopping_cb, tensorboard_cb, checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9622 - loss: 0.1148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.10299555957317352, 0.9682000279426575]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# restore best model\n",
    "model = tf.keras.models.load_model(\"mnist_model.keras\")\n",
    "\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
