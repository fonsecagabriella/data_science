{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bdec2d3",
   "metadata": {},
   "source": [
    "# ðŸ§  Enconders - Summary\n",
    "- Use OneHotEncoder when you want full control, need to work with sklearn pipelines, or must handle unknown categories safely.\n",
    "\n",
    "- Use DictVectorizer when your data is in dictionary format (e.g., JSON or from APIs) and you want to plug it into a pipeline quickly.\n",
    "\n",
    "- Use pd.get_dummies() for quick, simple transformations when you're staying inside pandas and not building a full ML pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d5ccb0",
   "metadata": {},
   "source": [
    "# OneHotEncoderâ€¯vs.â€¯DictVectorizer\n",
    "\n",
    "Two scikitâ€‘learn transformers that both turn categorical data into numerical vectorsâ€¯â€”â€¯but theyâ€™re built around **different mental models of your data**.\n",
    "\n",
    "| Feature | **OneHotEncoder** | **DictVectorizer** |\n",
    "|---------|------------------|--------------------|\n",
    "| **Data model** | *Columnâ€‘oriented table* (NumPy array or pandasâ€¯DataFrame). Each column has a fixed meaning. | *Bagâ€‘ofâ€‘features* (list/iterator of Pythonâ€¯dicts). Each `(key, value)` pair is an independent feature. |\n",
    "| **Typical raw input** | `pd.DataFrame` from CSV / SQL. | JSONâ€‘like records, log entries, API payloads. |\n",
    "| **How categories are discovered** | Per column: learns unique values *within* each column. | Each distinct `(key, value)` becomes its own feature name `key=value`. |\n",
    "| **Numeric features** | Must be handled separately (e.g., via `ColumnTransformer`). | Numeric *values* pass through unchanged; only strings are oneâ€‘hotâ€‘encoded. |\n",
    "| **Unknown categories at inference** | Controlled with `handle_unknown=('error', 'ignore', 'infrequent_if_exist')`. | New `(key, value)` raises an error unless preâ€‘declared. |\n",
    "| **Drop reference level** | Builtâ€‘in (`drop='first'`, `drop='if_binary'`). | Not builtâ€‘in; slice columns manually if needed. |\n",
    "| **Output format** | CSR sparse (default) or dense (`sparse_output=False`). | CSR sparse (default) or dense (`sparse=False`). |\n",
    "| **Inverse transform** | âœ”ï¸ Returns structured array/DataFrame. | âœ”ï¸ Returns list of dicts. |\n",
    "| **Best for** | Stable, tidy tabular data; fineâ€‘grained perâ€‘column control in pipelines. | Flexible, highâ€‘dimensional, sparse feature spaces from dict/JSON inputs. |\n",
    "\n",
    "---\n",
    "\n",
    "## Deeper Intuition\n",
    "\n",
    "- **OneHotEncoderâ€¯=â€¯â€œfixed schema, flexible values.â€**  \n",
    "  Think spreadsheet columns (*Color*, *Size*, *City*). Encoder catalogs possible values **within** each column and builds blockâ€‘wise oneâ€‘hot columns.\n",
    "\n",
    "- **DictVectorizerâ€¯=â€¯â€œflexible schema, keyâ€‘value explosion.â€**  \n",
    "  Logging events: each line can have different keys (`device=Android`, `browser=Chrome`, `temperature=21.4`). Every new `(key, value)` pair spawns a feature; numeric values flow through unchanged.\n",
    "\n",
    "---\n",
    "\n",
    "## Minimal Example\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62c4f7d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneHotEncoder output:\n",
      " [[0. 1. 0. 1. 0.]\n",
      " [1. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1.]]\n",
      "DictVectorizer output:\n",
      " [[0.  1.  0.  1.  0.  1.1]\n",
      " [1.  0.  1.  0.  0.  2. ]\n",
      " [0.  1.  0.  0.  1.  1.5]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    \"color\":  [\"red\", \"blue\", \"red\"],\n",
    "    \"size\":   [\"M\",   \"L\",    \"S\" ],\n",
    "    \"weight\": [1.1,    2.0,    1.5]\n",
    "})\n",
    "records = df.to_dict(orient=\"records\")    # [{'color':'red',...}, ...]\n",
    "\n",
    "# 1ï¸âƒ£ OneHotEncoder\n",
    "ohe = OneHotEncoder(sparse_output=False)\n",
    "X_ohe = ohe.fit_transform(df[[\"color\", \"size\"]])  # numeric handled elsewhere\n",
    "\n",
    "# 2ï¸âƒ£ DictVectorizer\n",
    "dv = DictVectorizer(sparse=False)\n",
    "X_dv = dv.fit_transform(records)\n",
    "\n",
    "\n",
    "print(\"OneHotEncoder output:\\n\", X_ohe)\n",
    "print(\"DictVectorizer output:\\n\", X_dv)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c344fd3a",
   "metadata": {},
   "source": [
    "### Resulting feature names\n",
    "\n",
    "| Encoder | Feature names |\n",
    "|---------|---------------|\n",
    "| **ohe** | `color=blue`, `color=red`, `size=L`, `size=M`, `size=S` |\n",
    "| **dv**  | `color=blue`, `color=red`, `size=L`, `size=M`, `size=S`, **`weight`** |\n",
    "\n",
    "`weight` automatically passes through with `DictVectorizer`.\n",
    "\n",
    "---\n",
    "\n",
    "### Quick Selection Guide\n",
    "\n",
    "1. **Tidy DataFrame â†’ OneHotEncoder** (use in a `ColumnTransformer`).\n",
    "2. **List of dictsâ€¯/â€¯JSON â†’ DictVectorizer** (zero friction).\n",
    "3. **Need to drop reference level or handle unseen categories gracefully â†’ OneHotEncoder**.\n",
    "4. **Just playing inside pandas, no pipeline â†’ `pd.get_dummies()`** is quickest, though less productionâ€‘friendly.\n",
    "\n",
    "> **Rule of thumb:** choose the transformer whose **input format matches your raw data** and whose **options match your production constraints** (memory, unknown categories, multicollinearity).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
