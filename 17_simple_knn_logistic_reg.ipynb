{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title\n",
    "\n",
    "**Exercise 2 - Simple k-NN Classification and Logistic Regression**\n",
    "\n",
    "# Description\n",
    "The aim of this exercise is to fit, interpret, predict, score, and plot simple $k$-NN classification and logistic regression models using the `sklearn` package.\n",
    "\n",
    "In the end, you should get a plot that looks like this (way too busy for publication, but OK here for teaching purposes):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/simple_knn_log_reg.png\" style=\"width: 500px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Description:\n",
    "\n",
    "The dataset used here is called the Heart dataset. This dataset has several predictors such as `Age`, `Sex`, and `MaxHR`, etc.  For now, we will just use `Age` to predict whether or not someone has atherosclerotic heart disease (AHD).\n",
    "\n",
    "# Instructions:\n",
    "1. Read the `Heart.csv` file into a pandas data frame.\n",
    "2. Split the dataset into train and validation sets, with 80% of the data for training\n",
    "3. Assign the predictor and response variables. Remember the aim is to predict whether a patient has `AHD`\n",
    "4. Fit a $k$-NN model (manually tuned) to the dataset and look at some predictions.\n",
    "5. Fit a logistic regression model to the dataset and interpret the coefficients. \n",
    "6. Do some work mathematically based on the estimated model.\n",
    "7. Compute and print the train and validation accuracies for both\n",
    "8. Plot the predictions on the scatterplot.\n",
    "\n",
    "# Hints:\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\" target=\"_blank\">sklearn.KNeighborsClassifier()</a> : Generates a $k$-NN classifier\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" target=\"_blank\">sklearn.LogisticRegression()</a> : Generates a Logistic Regression classifier\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit\" target=\"_blank\">sklearn.fit()</a> : Fits the model to the given data\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict\" target=\"_blank\">sklearn.predict()</a> : Predict using the estimated model (Logistic or knn classifiers) to perform pure classification predictions\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.predict_proba\" target=\"_blank\">sklearn.predict_proba()</a> : Predict using the estimated model (Logistic or knn classifiers) to perform probability predictions of all the classes in the response (they should add up to 1 for each observation)\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\" target=\"_blank\">sklearn.LogisticRegression.coef_ and .intercept_</a> : Pull off the estimated $\\beta$ coefficients in a Logistic Regression model\n",
    "\n",
    "<a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.score\" target=\"_blank\">sklearn.score()</a> : Accuracy classification score.\n",
    "\n",
    "**Note: This exercise is auto-graded and you can try multiple attempts.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r9/ggpr596s74x4hr8c_sfdzc580000gn/T/ipykernel_9676/4026302799.py:3: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read-in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(303, 15)\n"
     ]
    }
   ],
   "source": [
    "# Read the \"Heart.csv\" dataset and take a quick look\n",
    "heart = pd.read_csv('data/heart.csv')\n",
    "\n",
    "\n",
    "# Force the response into a binary indicator:\n",
    "heart['AHD'] = 1*(heart['AHD'] == \"Yes\")\n",
    "\n",
    "print(heart.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(227, 15) (76, 15)\n"
     ]
    }
   ],
   "source": [
    "# split into train and validation\n",
    "heart_train, heart_val = train_test_split(heart, train_size = 0.75, random_state = 109)\n",
    "\n",
    "print(heart_train.shape, heart_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN model fitting\n",
    "\n",
    "Define and fit a $k$-NN classification model with $k=20$ to predict `AHD` from `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=20)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select variables for model estimation: be careful of format \n",
    "# (aka, single or double square brackets)\n",
    "x_train = heart_train[[\"Age\"]]\n",
    "y_train = heart_train[\"AHD\"]\n",
    "\n",
    "# define the model\n",
    "knn20 = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "# fit to the data\n",
    "knn20.fit(x_train , y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN prediction\n",
    "\n",
    "Perform some simple predictions: both the pure classifications and the probability estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 1 0 0 1 0 1]\n",
      "[[0.75 0.25]\n",
      " [0.3  0.7 ]\n",
      " [0.25 0.75]\n",
      " [0.3  0.7 ]\n",
      " [0.65 0.35]\n",
      " [0.5  0.5 ]\n",
      " [0.3  0.7 ]\n",
      " [0.55 0.45]\n",
      " [0.35 0.65]]\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_knn) ###\n",
    "\n",
    "# there are two types of predictions in classification models in sklearn\n",
    "# model.predict for pure classifications, and model.predict_proba for probabilities\n",
    "\n",
    "# create the predictions based on the train data\n",
    "yhat20_class = knn20.predict(x_train)\n",
    "yhat20_prob = knn20.predict_proba(x_train)\n",
    "\n",
    "# print out the first 10 predictions for the actual data\n",
    "print(yhat20_class[1:10])\n",
    "print(yhat20_prob[1:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you notice about the probability estimates?  Which 'column' is which?  How could you manually create `yhat20_class` from `yhat20_prob`? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*, p=1 for each line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple logisitc regression model fitting\n",
    "\n",
    "Define and fit a $k$-NN classification model with $k=20$ to predict `AHD` from `Age`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Estimated Betas (B0,B1): -3.3261670337310845 0.05933142048457174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1182: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_logit) ###\n",
    "# Create a logistic regression model, with 'none' as the penalty\n",
    "\n",
    "logit1 = LogisticRegression(penalty=\"None\", max_iter = 1000)\n",
    "\n",
    "#Fit the model using the training set\n",
    "\n",
    "logit1.fit(x_train,y_train)\n",
    "\n",
    "# Get the coefficient estimates\n",
    "\n",
    "print(\"Logistic Regression Estimated Betas (B0,B1):\",logit1.intercept_[0],logit1.coef_[0][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the Coefficient Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down the logistic regression model below (edit the provided latex formula).  Use this formula to answer: \n",
    "\n",
    "What is the estimated odds that a 60 year old will have AHD in the ICU?  What is the probability?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\ln\\left(  \\frac{P(Y=1)}{1-P(Y=1)} \\right) = \\hat{\\beta}_0 + \\hat{\\beta}_1 X$$\n",
    "\n",
    "*your answer here\n",
    "Probability +/- 23%\n",
    "\n",
    "B0 = -3.32\n",
    "B1 = 0.05\n",
    "\n",
    "f(60) = B0 + B1 * 60\n",
    "*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction  [1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Make the predictions on the training & validation set\n",
    "# Be careful as to how you define the new observation.  Hint: double brackets is one way to do it\n",
    "\n",
    "pred_v = logit1.predict([[60]])\n",
    "\n",
    "print(\"Prediction \", pred_v[:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $k$-NN and logistic accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-NN Train & Validation Accuracy: 0.6563876651982379 0.6052631578947368\n",
      "Logisitic Train & Validation Accuracy: 0.6387665198237885 0.6052631578947368\n"
     ]
    }
   ],
   "source": [
    "### edTest(test_accuracy) ###\n",
    "\n",
    "# Define the equivalent validation variables from `heart_val`\n",
    "\n",
    "x_val = heart_val[[\"Age\"]]\n",
    "y_val = heart_val[\"AHD\"]\n",
    "\n",
    "# Compute the training & validation accuracy using the estimator.score() function\n",
    "\n",
    "knn20_train_accuracy = knn20.score(x_train, y_train)\n",
    "knn20_val_accuracy = knn20.score(x_val, y_val)\n",
    "\n",
    "logit_train_accuracy = logit1.score(x_train, y_train)\n",
    "logit_val_accuracy = logit1.score(x_val, y_val)\n",
    "\n",
    "# Print the accuracies below\n",
    "\n",
    "print(\"k-NN Train & Validation Accuracy:\", knn20_train_accuracy, knn20_val_accuracy)\n",
    "print(\"Logisitic Train & Validation Accuracy:\", logit_train_accuracy, logit_val_accuracy)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a 'dummy' x variable for plotting for the two different models.  Here we plot the train and validation data separately, and the 4 different types of predictions (2 for each model: pure classification and probability estimation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:464: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[19.         19.10050251 19.20100503 19.30150754 19.40201005 19.50251256\n 19.60301508 19.70351759 19.8040201  19.90452261 20.00502513 20.10552764\n 20.20603015 20.30653266 20.40703518 20.50753769 20.6080402  20.70854271\n 20.80904523 20.90954774 21.01005025 21.11055276 21.21105528 21.31155779\n 21.4120603  21.51256281 21.61306533 21.71356784 21.81407035 21.91457286\n 22.01507538 22.11557789 22.2160804  22.31658291 22.41708543 22.51758794\n 22.61809045 22.71859296 22.81909548 22.91959799 23.0201005  23.12060302\n 23.22110553 23.32160804 23.42211055 23.52261307 23.62311558 23.72361809\n 23.8241206  23.92462312 24.02512563 24.12562814 24.22613065 24.32663317\n 24.42713568 24.52763819 24.6281407  24.72864322 24.82914573 24.92964824\n 25.03015075 25.13065327 25.23115578 25.33165829 25.4321608  25.53266332\n 25.63316583 25.73366834 25.83417085 25.93467337 26.03517588 26.13567839\n 26.2361809  26.33668342 26.43718593 26.53768844 26.63819095 26.73869347\n 26.83919598 26.93969849 27.04020101 27.14070352 27.24120603 27.34170854\n 27.44221106 27.54271357 27.64321608 27.74371859 27.84422111 27.94472362\n 28.04522613 28.14572864 28.24623116 28.34673367 28.44723618 28.54773869\n 28.64824121 28.74874372 28.84924623 28.94974874 29.05025126 29.15075377\n 29.25125628 29.35175879 29.45226131 29.55276382 29.65326633 29.75376884\n 29.85427136 29.95477387 30.05527638 30.15577889 30.25628141 30.35678392\n 30.45728643 30.55778894 30.65829146 30.75879397 30.85929648 30.95979899\n 31.06030151 31.16080402 31.26130653 31.36180905 31.46231156 31.56281407\n 31.66331658 31.7638191  31.86432161 31.96482412 32.06532663 32.16582915\n 32.26633166 32.36683417 32.46733668 32.5678392  32.66834171 32.76884422\n 32.86934673 32.96984925 33.07035176 33.17085427 33.27135678 33.3718593\n 33.47236181 33.57286432 33.67336683 33.77386935 33.87437186 33.97487437\n 34.07537688 34.1758794  34.27638191 34.37688442 34.47738693 34.57788945\n 34.67839196 34.77889447 34.87939698 34.9798995  35.08040201 35.18090452\n 35.28140704 35.38190955 35.48241206 35.58291457 35.68341709 35.7839196\n 35.88442211 35.98492462 36.08542714 36.18592965 36.28643216 36.38693467\n 36.48743719 36.5879397  36.68844221 36.78894472 36.88944724 36.98994975\n 37.09045226 37.19095477 37.29145729 37.3919598  37.49246231 37.59296482\n 37.69346734 37.79396985 37.89447236 37.99497487 38.09547739 38.1959799\n 38.29648241 38.39698492 38.49748744 38.59798995 38.69849246 38.79899497\n 38.89949749 39.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(np\u001b[38;5;241m.\u001b[39mmin(heart[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m,np\u001b[38;5;241m.\u001b[39mmin(heart[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m]])\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m200\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# be careful in pulling off only the correct column of the probability calculations: use `[:,1]`\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m yhat_class_knn20 \u001b[38;5;241m=\u001b[39m \u001b[43mknn20\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m yhat_prob_knn20 \u001b[38;5;241m=\u001b[39m knn20\u001b[38;5;241m.\u001b[39mpredict_proba(x)[:, \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m      9\u001b[0m yhat_class_logit \u001b[38;5;241m=\u001b[39m logit1\u001b[38;5;241m.\u001b[39mpredict(x)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:261\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_[np\u001b[38;5;241m.\u001b[39margmax(probabilities, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;66;03m# In that case, we do not need the distances to perform\u001b[39;00m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;66;03m# the weighting so we do not compute them.\u001b[39;00m\n\u001b[0;32m--> 261\u001b[0m     neigh_ind \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m     neigh_dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/neighbors/_base.py:804\u001b[0m, in \u001b[0;36mKNeighborsMixin.kneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    802\u001b[0m         X \u001b[38;5;241m=\u001b[39m _check_precomputed(X)\n\u001b[1;32m    803\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 804\u001b[0m         X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m n_samples_fit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_samples_fit_\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_neighbors \u001b[38;5;241m>\u001b[39m n_samples_fit:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[19.         19.10050251 19.20100503 19.30150754 19.40201005 19.50251256\n 19.60301508 19.70351759 19.8040201  19.90452261 20.00502513 20.10552764\n 20.20603015 20.30653266 20.40703518 20.50753769 20.6080402  20.70854271\n 20.80904523 20.90954774 21.01005025 21.11055276 21.21105528 21.31155779\n 21.4120603  21.51256281 21.61306533 21.71356784 21.81407035 21.91457286\n 22.01507538 22.11557789 22.2160804  22.31658291 22.41708543 22.51758794\n 22.61809045 22.71859296 22.81909548 22.91959799 23.0201005  23.12060302\n 23.22110553 23.32160804 23.42211055 23.52261307 23.62311558 23.72361809\n 23.8241206  23.92462312 24.02512563 24.12562814 24.22613065 24.32663317\n 24.42713568 24.52763819 24.6281407  24.72864322 24.82914573 24.92964824\n 25.03015075 25.13065327 25.23115578 25.33165829 25.4321608  25.53266332\n 25.63316583 25.73366834 25.83417085 25.93467337 26.03517588 26.13567839\n 26.2361809  26.33668342 26.43718593 26.53768844 26.63819095 26.73869347\n 26.83919598 26.93969849 27.04020101 27.14070352 27.24120603 27.34170854\n 27.44221106 27.54271357 27.64321608 27.74371859 27.84422111 27.94472362\n 28.04522613 28.14572864 28.24623116 28.34673367 28.44723618 28.54773869\n 28.64824121 28.74874372 28.84924623 28.94974874 29.05025126 29.15075377\n 29.25125628 29.35175879 29.45226131 29.55276382 29.65326633 29.75376884\n 29.85427136 29.95477387 30.05527638 30.15577889 30.25628141 30.35678392\n 30.45728643 30.55778894 30.65829146 30.75879397 30.85929648 30.95979899\n 31.06030151 31.16080402 31.26130653 31.36180905 31.46231156 31.56281407\n 31.66331658 31.7638191  31.86432161 31.96482412 32.06532663 32.16582915\n 32.26633166 32.36683417 32.46733668 32.5678392  32.66834171 32.76884422\n 32.86934673 32.96984925 33.07035176 33.17085427 33.27135678 33.3718593\n 33.47236181 33.57286432 33.67336683 33.77386935 33.87437186 33.97487437\n 34.07537688 34.1758794  34.27638191 34.37688442 34.47738693 34.57788945\n 34.67839196 34.77889447 34.87939698 34.9798995  35.08040201 35.18090452\n 35.28140704 35.38190955 35.48241206 35.58291457 35.68341709 35.7839196\n 35.88442211 35.98492462 36.08542714 36.18592965 36.28643216 36.38693467\n 36.48743719 36.5879397  36.68844221 36.78894472 36.88944724 36.98994975\n 37.09045226 37.19095477 37.29145729 37.3919598  37.49246231 37.59296482\n 37.69346734 37.79396985 37.89447236 37.99497487 38.09547739 38.1959799\n 38.29648241 38.39698492 38.49748744 38.59798995 38.69849246 38.79899497\n 38.89949749 39.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "\n",
    "# set-up the dummy x for plotting: we extend it a little bit beyond the range of observed values \n",
    "x = np.linspace(np.min(heart[['Age']])-10,np.min(heart[['Age']])+10,200)\n",
    "\n",
    "\n",
    "# be careful in pulling off only the correct column of the probability calculations: use `[:,1]`\n",
    "yhat_class_knn20 = knn20.predict(x)\n",
    "yhat_prob_knn20 = knn20.predict_proba(x)[:, 1]\n",
    "\n",
    "yhat_class_logit = logit1.predict(x)\n",
    "yhat_prob_logit = logit1.predict_proba(x)[:, 1]\n",
    "\n",
    "# plot the observed data.  Note: we offset the validation points to make them more clearly differentiated from train\n",
    "plt.plot(x_train, y_train, 'o' ,alpha=0.1, label='Train Data')\n",
    "plt.plot(x_val, 0.94*y_val+0.03, 'o' ,alpha=0.1, label='Validation Data')\n",
    "\n",
    "# plot the predictions\n",
    "plt.plot(x, yhat_class_knn20, label='knn20 Classifications')\n",
    "plt.plot(x, yhat_prob_knn20, label='knn20 Probabilities')\n",
    "plt.plot(x, yhat_class_logit, label='logit1 Classifications')\n",
    "plt.plot(x, yhat_prob_logit, label='logit1 Probabilities')\n",
    "\n",
    "# put the lower-left part of the legend 5% to the right along the x-axis, and 45% up along the y-axis\n",
    "plt.legend(loc=(0.05,0.45))\n",
    "\n",
    "# Don't forget your axis labels!\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Heart disease (AHD)\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post exercise questions\n",
    "\n",
    "1. Describe the estimated associations between AHD and Age based on these two models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Which model apears to be more overfit to the training data?  How do you know?  How can this be resolved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. How could you engineer features for the logistic regression model so that the association between AHD and Age resembles the general trend in the knn20 model more similarly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Refit the models above to predict `AHD` from 3 predictors (please also play around with $k$):\n",
    "```{python}\n",
    "['MaxHR','Age','Sex']\n",
    "```\n",
    "Investigate the associations in each of the two models and evaluate the predictive accuracy of each of these models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
